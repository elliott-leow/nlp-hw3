INFO:probs:Read vocab of size 3439 from vocab-genspam.txt
INFO:train_lm:Training...
INFO:probs:=== Extended Log-Linear Training on 23268 tokens ===
INFO:probs:Config: dropout=0.1, batch_size=512, grad_accum=1, l2=0.01
INFO:probs:Features: unigram indicators+embeddings, trigram embeddings, spelling, repetition
INFO:probs:Total steps: 45
INFO:probs:
============================================================
INFO:probs:Epoch 1/1
INFO:probs:============================================================
INFO:probs:
Epoch 1 complete: avg_loss=277563.7816
INFO:probs:*** New best loss: 277563.7816 ***
INFO:probs:
============================================================
INFO:probs:Training complete! Best loss: 277563.7816
INFO:probs:============================================================
INFO:probs:Saving model to spam.model
INFO:probs:Saved model to spam.model
